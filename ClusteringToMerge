Clustering

%md
## Clustering with K-means

%spark
import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.ml.feature.VectorAssembler

// Loads data.
val dataset = trainData

// dataset.printSchema()

// transform datasetDf with VectorAssembler to add feature column
val cols = Array("user", "artist") // TODO : DETERMINER LES FEATURES A METTRE EN OEUVRE
val assembler = new VectorAssembler().setInputCols(cols).setOutputCol("features")
val featureDf = assembler.transform(dataset)

// featureDf.printSchema()

// featureDf.show(10)

// kmeans model with 8 clusters
val kmeans = new KMeans()
  .setK(8)
  .setFeaturesCol("features")
  .setPredictionCol("prediction")
val kmeansModel = kmeans.fit(featureDf)
kmeansModel.clusterCenters.foreach(println)

// test the model with test data set
val testData = List() // TODO FAIRE DES DATAS DE TEST
val predictDf = kmeansModel.transform(testData)
predictDf.show(10)

// no of categories
predictDf.groupBy("prediction").count().show()




------------------



%md
## Clustering with Gaussian Mixture Model (GMM)



%spark
import org.apache.spark.ml.clustering.GaussianMixture

// Loads data
val dataset = trainData

// transform datasetDf with VectorAssembler to add feature column
val cols = Array("user", "artist") // TODO : DETERMINER LES FEATURES A METTRE EN OEUVRE
val assembler = new VectorAssembler().setInputCols(cols).setOutputCol("features")
val featureDf = assembler.transform(dataset)

// Trains Gaussian Mixture Model
val gmm = new GaussianMixture()
  .setK(2)
val model = gmm.fit(featureDf)

val testData = List() // TODO FAIRE DES DATAS DE TEST
val predictDf = model.transform(testData)

// output parameters of mixture model model
for (i <- 0 until model.getK) {
  println(s"Gaussian $i:\nweight=${model.weights(i)}\n" +
      s"mu=${model.gaussians(i).mean}\nsigma=\n${model.gaussians(i).cov}\n")
}
